---
author: Dipankar Das
---

the 2 primary impacts on your concurrency are the invocations model of the event source thats triggering lambda and the service limits of the amazon web services services ypu use

Both synchronous and asynchronous event sources measure concurrency as the request rate, multiplied by the average duration of a function. If you exceed available concurrency, requests will be throttled.

For example, if your function lasts 10 seconds on average, and there are 25 requests per second, your concurrency is 250 concurrent invocations of that function. If your available concurrency is less than 250, requests will be throttled. Remember that there could be function concurrency limits in addition to the account limit.

Which of these statements about serverless scaling are true? (Select THREE.)

- [x] With serverless, you don’t need to set up Auto Scaling groups and subnets because you’re using managed services that have built-in horizontal scaling, security, and high availability.
- [x] You need to evaluate trade-offs across the architecture; look at service limits end to end to identify potential bottlenecks; and balance performance requirements, costs, and business impact.
- [x] When functions are throttled, synchronous and asynchronous event sources will retry twice to invoke the function, but only asynchronous failures can be sent to a dead-letter queue.
- [x] For asynchronous sources, concurrency is measured as average function duration * request rate. For streaming invocations, there is a limit of one concurrent invocation per shard.

